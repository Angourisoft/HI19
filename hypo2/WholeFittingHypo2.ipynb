{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A to Z fitting HI model according to Hypo 2 (combined model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypo2.api import RunTime, FitTime\n",
    "from hypo2.config import RunConfig\n",
    "import os\n",
    "from hypo2.dataset import Dataset\n",
    "from hypo2.model import HIModel\n",
    "import hypo2.api as api\n",
    "import random\n",
    "import numpy as np\n",
    "from hypo2.preprocessing import WordSegmentator\n",
    "from hypo2.normalization import Normalizator\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision.models.inception import Inception3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = FitTime.gen_paths(\"C:/ml_prj/SchoolHWA/data2\")\n",
    "config.CLASS_COUNT = 2\n",
    "ws = WordSegmentator(config)\n",
    "nm = Normalizator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset(config, ws, nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0 % 57.14 %\n"
     ]
    }
   ],
   "source": [
    "#X, y = ds.gen_dataset([paths[0] + paths[1], paths[2]], True)\n",
    "X, y = ds.gen_dataset([paths[-1], paths[-3]], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xl = list(X)\n",
    "yl = list(y)\n",
    "i = 0\n",
    "while i < len(Xl):\n",
    "    if Xl[i].mean() < -0.46:\n",
    "        del Xl[i]\n",
    "        del yl[i]\n",
    "    else:\n",
    "        i += 1\n",
    "X = np.stack(Xl)\n",
    "y = np.stack(yl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(res, pattern):\n",
    "    before_0 = -(res.shape[1] - pattern[0]) // 2\n",
    "    after_0 = -(res.shape[1] - pattern[0]) // 2 + (res.shape[1] - pattern[0]) % 2\n",
    "    before_1 = -(res.shape[0] - pattern[1]) // 2\n",
    "    after_1 = -(res.shape[0] - pattern[1]) // 2 + (res.shape[0] - pattern[1]) % 2\n",
    "    return np.pad(res, [(before_1, after_1), (before_0, after_0), (0, 0)], mode=\"constant\", constant_values=1)\n",
    "\n",
    "def add_padding_4(res, pattern):\n",
    "    before_0 = -(res.shape[3] - pattern[0]) // 2\n",
    "    after_0 = -(res.shape[3] - pattern[0]) // 2 + (res.shape[3] - pattern[0]) % 2\n",
    "    before_1 = -(res.shape[2] - pattern[1]) // 2\n",
    "    after_1 = -(res.shape[2] - pattern[1]) // 2 + (res.shape[2] - pattern[1]) % 2\n",
    "    return np.pad(res, [(0, 0), (0, 0), (before_1, after_1), (before_0, after_0)], mode=\"constant\", constant_values=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FF = int((1 - y.mean()) * len(X))\n",
    "dX1 = list(X[:FF])\n",
    "dX2 = list(X[FF:])\n",
    "dXtest1 = []\n",
    "dXtest2 = []\n",
    "for i in range((len(dX1) + len(dX2)) // 7):\n",
    "    f1 = random.randint(0, len(dX1) - 1)\n",
    "    f2 = random.randint(0, len(dX2) - 1)\n",
    "    dXtest1.append(dX1[f1])\n",
    "    dXtest2.append(dX2[f2])\n",
    "    del dX1[f1]\n",
    "    del dX2[f2]\n",
    "dX1 = np.stack(dX1)\n",
    "dX2 = np.stack(dX2)\n",
    "dX = [dX1, dX2]\n",
    "dXtest1 = np.stack(dXtest1)\n",
    "dXtest2 = np.stack(dXtest2)\n",
    "dXtest = [dXtest1, dXtest2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dX1.shape, dX2.shape, dXtest1.shape, dXtest2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def resort_and_noise(dX, dX1, dX2, samples):\n",
    "    rX1 = []\n",
    "    rX2 = []\n",
    "    ry = []\n",
    "    for i in range(samples):\n",
    "        if i % 1000 == 999:\n",
    "            print(i)\n",
    "        if random.random() > 0.5:\n",
    "            source = random.choice(dX)\n",
    "            t1 = random.choice(source)\n",
    "            t2 = random.choice(source)\n",
    "            ry.append(1.0)\n",
    "        else:\n",
    "            t1 = random.choice(dX1)\n",
    "            t2 = random.choice(dX2)\n",
    "            ry.append(0.0)\n",
    "        #t1noise = np.stack([np.random.randn(299, 299)] * 3, axis=2) / 30\n",
    "        #t2noise = np.stack([np.random.randn(299, 299)] * 3, axis=2) / 30\n",
    "        #t1 += t1noise\n",
    "        #t2 += t2noise\n",
    "        rX1.append(t1)\n",
    "        rX2.append(t2)\n",
    "\n",
    "    fX1 = torch.from_numpy(np.stack(rX1)).transpose(1, 3).transpose(2, 3).type(torch.float)\n",
    "    fX2 = torch.from_numpy(np.stack(rX2)).transpose(1, 3).transpose(2, 3).type(torch.float)\n",
    "    fy = torch.tensor(ry)\n",
    "    return fX1, fX2, fy\n",
    "\n",
    "fX1, fX2, fy = resort_and_noise(dX, dX1, dX2, 45000)\n",
    "fXtest1, fXtest2, ftesty = resort_and_noise(dXtest, dXtest1, dXtest2, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  Первый человек\" + \" \" * 45 + \"Второй человек\")\n",
    "fig = plt.figure(figsize=[16, 16])\n",
    "for i in range(36):\n",
    "    plt.subplot(18,2,i+1)\n",
    "    if i % 2 == 1:\n",
    "        plt.imshow(dX2[i] + 1/2)\n",
    "    else:\n",
    "        plt.imshow(dX1[i] + 1/2)\n",
    "    fig.axes[i].get_xaxis().set_visible(False)\n",
    "    fig.axes[i].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.figure(figsize=[16, 2])\n",
    "    print(\"Один и тот же человек:\" if fy[i] == 0 else \"Разные люди:\")\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(fX1[i].transpose(0, 2).transpose(0, 1) + 0.5)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(fX2[i].transpose(0, 2).transpose(0, 1) + 0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Consumed memory:\", round(2 * fX1.shape[0] * fX1.shape[1] * fX1.shape[2] * fX1.shape[3] * 4 / 1000000000, 1), \"Gb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lllll = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "            nn.Conv2d(3, 3, kernel_size=[3, 3], padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Conv2d(3, 3, kernel_size=[3, 3], padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Conv2d(3, 3, kernel_size=[3, 3], padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Conv2d(3, 3, kernel_size=[3, 3], padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            '''\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp__(r):\n",
    "    s = 1\n",
    "    for i in r:\n",
    "        s *= i\n",
    "    return s\n",
    "\n",
    "class Sigm(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 1 / (1 + 1.4 ** (-(x - 5)))\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.reshape(x.shape[0], (mp__(x.shape[1:])))\n",
    "\n",
    "class MultiKernelLayer(nn.Module):\n",
    "    def __init__(self, kernels, dev, ch=3):\n",
    "        super().__init__()\n",
    "        self.lenk = len(kernels)\n",
    "        for i in range(self.lenk):\n",
    "            exec(\"self.module\" + str(i) + \" = nn.Conv2d(ch, ch, kernel_size=kernels[i], padding=kernels[i]//2).to(dev)\")\n",
    "        self.final = nn.BatchNorm2d(ch)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        r = 0\n",
    "        for i in range(self.lenk):\n",
    "            r += eval(\"self.module\" + str(i) + \"(x)\")\n",
    "        return self.final(r)\n",
    "    \n",
    "class DyPa(nn.Module):\n",
    "    def __init__(self, layer_count, kernels, size, class_count, dev):\n",
    "        super().__init__()\n",
    "        for i in range(layer_count):\n",
    "            exec(\"self.layer\" + str(i) + \" = MultiKernelLayer(kernels, dev)\")\n",
    "        self.layer_count = layer_count\n",
    "        self.final = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(size[0] * size[1] * 3, class_count),\n",
    "            Sigm()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        r = 0\n",
    "        x1 = x\n",
    "        for layer in range(self.layer_count):\n",
    "            f = eval(\"self.layer\" + str(layer) + \"(x1)\")\n",
    "            r += f\n",
    "            x1 = f\n",
    "        return self.final(r)\n",
    "        \n",
    "    \n",
    "class FixedInc3(nn.Module):\n",
    "    def __init__(self, CLASS_COUNT, dev):\n",
    "        super().__init__()\n",
    "        self.t = Inception3(CLASS_COUNT)\n",
    "        '''\n",
    "        self.t = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, kernel_size=[3, 3], padding=1),\n",
    "            nn.BatchNorm2d(3),\n",
    "            Flatten(),\n",
    "            nn.Linear(299 * 299 * 3, CLASS_COUNT),\n",
    "            Sigm()\n",
    "        )\n",
    "        '''\n",
    "        #self.t = DyPa(15, [3, 5, 7, 9, 11, 13, 15], (299, 299), CLASS_COUNT, dev)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.t(x)[0]\n",
    "    \n",
    "class Siames(nn.Module):\n",
    "    def __init__(self, cfg, device):\n",
    "        super().__init__()\n",
    "        self.tw = FixedInc3(cfg.FEATURES_COUNT, device)\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.comparator = nn.Sequential(\n",
    "            #nn.Linear(cfg.FEATURES_COUNT, cfg.FEATURES_COUNT),\n",
    "            #Norm(),\n",
    "            nn.Linear(cfg.FEATURES_COUNT, cfg.FEATURES_COUNT),\n",
    "            Norm(),\n",
    "            nn.Linear(cfg.FEATURES_COUNT, cfg.FEATURES_COUNT),\n",
    "            Norm(),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(cfg.FEATURES_COUNT, 1),\n",
    "            #Norm(),\n",
    "            #nn.Sigmoid()\n",
    "            Sigm()\n",
    "        )\n",
    "        \n",
    "        self.mp = (torch.zeros((300, 1)) + 1).type(torch.float).to(device)\n",
    "        self.sig = Sigm()\n",
    "    def forward(self, x1, x2):\n",
    "        f1 = self.tw(x1)\n",
    "        #print(\"1:\", f1[0][0])\n",
    "        f2 = self.tw(x2)\n",
    "        #print(\"2:\", f2[0][0])\n",
    "        f3 = (f1 - f2) ** 2 * 0.003\n",
    "        #print(\"3:\", f3[0][0])\n",
    "        #print(f3.mean())\n",
    "        #lllll.append(f3)\n",
    "        #return self.comparator(f3)\n",
    "        f4 = torch.mm(f3, self.mp)\n",
    "        #print(\"4:\", f4[0][0])\n",
    "        return self.sig(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Siames(config, torch.device(\"cuda\")).to(DEVICE)\n",
    "model = torch.load(\"D:/main/ml_prj/SchoolHWA/siames_models/hi1559451128.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.randn((5, 3, 299, 299)).to(DEVICE), torch.randn((5, 3, 299, 299)).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtime_preprocess(bX, dev):\n",
    "    bX = torch.tensor(add_padding_4(1 - (bX + 1/2), (299, 299)))\n",
    "    tnoise = torch.from_numpy(np.stack([np.stack([np.random.randn(299, 299)] * 3, axis=2) / 30 for j in range(bX.shape[0])])).transpose(1, 3)\n",
    "    return 1 - (bX + tnoise.type(torch.float)).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tttttttttttttttttest():\n",
    "    batchid = random.randint(0, len(fX1) - BS - 1)\n",
    "    bX1 = runtime_preprocess(fX1[batchid:batchid+BS], DEVICE)\n",
    "    bX2 = runtime_preprocess(fX2[batchid:batchid+BS], DEVICE)\n",
    "    ytrue = fy[batchid:batchid+BS].to(DEVICE)\n",
    "    ypred = model(bX1, bX2)\n",
    "    return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=1.0e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfloss(pred, true):\n",
    "    return ((pred - true) ** 2 * (torch.abs(pred - 0.5) + 0.1)).mean()\n",
    "#crit = mfloss\n",
    "crit = nn.BCELoss()\n",
    "#crit = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "losses = []\n",
    "all = 0\n",
    "s = 0\n",
    "accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    batchid = random.randint(0, len(fX1) - BS - 1)\n",
    "    bX1 = runtime_preprocess(fX1[batchid:batchid+BS], DEVICE)\n",
    "    bX2 = runtime_preprocess(fX2[batchid:batchid+BS], DEVICE)\n",
    "    ytrue = fy[batchid:batchid+BS].to(DEVICE)\n",
    "    ypred = model(bX1, bX2)\n",
    "    loss = crit(ypred, ytrue)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    losses.append(loss.item())\n",
    "    clear_output(True)\n",
    "    \n",
    "    _all = BS\n",
    "    _s = (BS - ((ypred.reshape(BS) > 0.5).type(torch.float) - (ytrue.reshape(BS) > 0.5).type(torch.float)).abs().sum()).item()\n",
    "    all += _all\n",
    "    s += _s\n",
    "    acc = _s / _all\n",
    "    accs.append(acc)\n",
    "    \n",
    "    plt.plot(losses, label=\"loss\")\n",
    "    #plt.plot(accs, label=\"acc\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#torch.save(model, \"D:/main/ml_prj/SchoolHWA/siames_models/hi\" + str(int(time.time())) + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Train accuracy:\", sum(accs[-90:]) / len(accs[-90:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = 0\n",
    "s = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(300):\n",
    "    batchid = random.randint(0, len(fXtest1) - BS - 1)\n",
    "    bX1 = runtime_preprocess(fXtest1[batchid:batchid+BS], DEVICE)\n",
    "    bX2 = runtime_preprocess(fXtest2[batchid:batchid+BS], DEVICE)\n",
    "    ytrue = ftesty[batchid:batchid+BS].to(DEVICE)\n",
    "    ypred = model(bX1, bX2)\n",
    "    all += BS\n",
    "    s += (BS - ((ypred.reshape(BS) > 0.5).type(torch.float) - (ytrue.reshape(BS) > 0.5).type(torch.float)).abs().sum()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Final accuracy:\", s / all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
